<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<title>景深的实现技术 | wingstone's blog</title>
<link rel=stylesheet href=/css/style.css>
<link rel=stylesheet href=/css/fonts.css>
<link rel=icon href=/icons/16.png>
</head>
<body>
<nav>
<ul class=menu>
<li><a href=/ class=menu-item>Home</a></li>
<li><a href=/categories/ class=menu-item>Categories</a></li>
<li><a href=/tags/ class=menu-item>Tags</a></li>
<li><a href=/archives/ class=menu-item>Archives</a></li>
<li><a href=/about/ class=menu-item>About</a></li>
<li><a href=/index.xml class=menu-item>Subscribe</a></li>
</ul>
<hr>
</nav>
<div class=article-meta>
<h2><span class=title>景深的实现技术</span></h2>
<h3 class=date>2020/10/20</h3>
</div><h2>目录</h2>
<nav id=TableOfContents>
<ul>
<li><a href=#基于光线追踪的景深效果离线>基于光线追踪的景深效果（离线）</a></li>
<li><a href=#基于累积贴图的景深效果实时>基于累积贴图的景深效果（实时）</a></li>
<li><a href=#基于分层绘制的景深效果实时>基于分层绘制的景深效果（实时）</a></li>
<li><a href=#基于前向映射的z-buffer的景深效果实时>基于前向映射的Z-buffer的景深效果（实时）</a></li>
<li><a href=#基于反向映射的z-buffer的景深效果实时>基于反向映射的Z-buffer的景深效果（实时）</a></li>
<li><a href=#reference>Reference</a></li>
</ul>
</nav>
<main>
<p>景深的实现技术有很多，针对不同的使用场景，可以使用不同的方法；</p>
<h2 id=基于光线追踪的景深效果离线>基于光线追踪的景深效果（离线）</h2>
<p>基于光线追踪的景深效果，直接使用薄透镜模型，在透镜上面进行多采样即可实现景深效果；</p>
<p>关于薄透镜理论的使用，可以参考这里<a href=https://zhuanlan.zhihu.com/p/23827065>基于摄影参数渲染</a>;</p>
<h2 id=基于累积贴图的景深效果实时>基于累积贴图的景深效果（实时）</h2>
<p>大致思路为，将相机进行移动（可按照透镜多采样的方式移动），沿焦平面进行多个相机的渲染，然后将渲染结果进行累加，这样就能获取与光线追踪类似的效果；本质上类似于光线追踪的多采样方式，但需要花费大量的DC，一般只用来验证；</p>
<h2 id=基于分层绘制的景深效果实时>基于分层绘制的景深效果（实时）</h2>
<p>本质上，是基于2D图层的方式来实现；将场景按深度进行分层绘制，然后将远离焦距的绘制rt记性模糊，然后按层进行混合，即可获取接近景深的效果；</p>
<p>使用要求时，不同的景物之间不能有交叉，即物体不能有太强的深度变化；因为针对单个物体是无法产生即聚焦又失焦的现象；</p>
<h2 id=基于前向映射的z-buffer的景深效果实时>基于前向映射的Z-buffer的景深效果（实时）</h2>
<p>此方法常用在后处理效果中，该方法存储颜色缓冲与深度缓冲作为最后的blit对象；然后使用深度缓冲计算COC（circle of confusion），即点投影在屏幕上形成的弥散圆；再然后利用弥散圆进行模糊与blend，这里模糊并不是通常意义上的模糊，模糊需要的圆盘采样与普通模糊一致，但是采样的判定需要根据采样点的COC是否能覆盖到当前点，来确定该采样点的弥散圆是否对当前点有贡献；GPU Gems中说blend只能混合到距离摄像机比自己远的那些相邻像素中，以避免模糊的像素影响它们前面的清晰像素。实际上，blend的是为了避免前面模糊造成聚焦物体边缘的消失；</p>
<h2 id=基于反向映射的z-buffer的景深效果实时>基于反向映射的Z-buffer的景深效果（实时）</h2>
<p>该方法与上一种技术类似，区别在于并不是通过blend来形成最后的图像，而是通过使用深度值距焦距的距离来进行blur，从而形成最终的效果；这里把当前点的弥散圆当做模糊范围来进行计算了，与实际的PBR有些偏差，但也能凑活使用；</p>
<h2 id=reference>Reference</h2>
<ol>
<li><a href=https://catlikecoding.com/unity/tutorials/advanced-rendering/depth-of-field/>Depth of Field</a></li>
<li><a href=https://developer.nvidia.com/gpugems/gpugems/part-iv-image-processing/chapter-23-depth-field-survey-techniques>Depth of Field: A Survey of Techniques</a></li>
<li><a href=https://zhuanlan.zhihu.com/p/23827065>基于摄影参数渲染</a></li>
<li><a href=https://zhuanlan.zhihu.com/p/146143501>渲染中的景深(Depth of Field/DOF)</a></li>
<li><a href=https://epicgames.ent.box.com/s/s86j70iamxvsuu6j35pilypficznec04>A Life of a Bokeh - SIGGRAPH 2018</a></li>
</ol>
</main>
<footer>
<script defer src=//yihui.org/js/math-code.js></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script defer src=//yihui.org/js/center-img.js></script>
<hr>
© <a href=https://wingstone.github.io>wingstone</a> 2020 &ndash; 2022 | <a href=https://github.com/wingstone>Github</a> | <a href=https://www.zhihu.com/people/wu-zhu-32-40>Zhihu</a> | <a href=https://www.shadertoy.com/user/wingstone>Shadertoy</a>
</footer>
</body>
</html>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>